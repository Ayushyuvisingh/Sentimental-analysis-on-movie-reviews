{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvJM0c2_Phsu",
        "outputId": "b9e44377-8750-4e99-e7db-a33d48fa82b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('IMDB Dataset.csv')\n",
        "\n",
        "print(\"Dataset Head:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()\n",
        "\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "print(\"\\nFirst 5 rows after mapping sentiment to numbers:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM4R67d0PwWE",
        "outputId": "392e0684-d7ac-4d00-d6c3-e427925ae85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Head:\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n",
            "\n",
            "First 5 rows after mapping sentiment to numbers:\n",
            "                                              review  sentiment\n",
            "0  One of the other reviewers has mentioned that ...          1\n",
            "1  A wonderful little production. <br /><br />The...          1\n",
            "2  I thought this was a wonderful way to spend ti...          1\n",
            "3  Basically there's a family where a little boy ...          0\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Function to clean the review text.\n",
        "    - Removes HTML tags\n",
        "    - Removes punctuation and special characters\n",
        "    - Converts to lowercase\n",
        "    - Removes stop words\n",
        "    \"\"\"\n",
        "    # 1. Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # 2. Remove punctuation and non-alphabetic characters\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "\n",
        "    # 3. Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 4. Tokenize the text (split into words)\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # 5. Remove stop words\n",
        "    cleaned_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    return ' '.join(cleaned_words)\n",
        "\n",
        "# Apply the cleaning function to the 'review' column\n",
        "print(\"\\nCleaning text data... this may take a moment.\")\n",
        "df['cleaned_review'] = df['review'].apply(clean_text)\n",
        "\n",
        "print(\"Cleaning complete. Here's a comparison:\")\n",
        "print(\"\\nOriginal Review:\")\n",
        "print(df['review'][0])\n",
        "print(\"\\nCleaned Review:\")\n",
        "print(df['cleaned_review'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQxmG7__elb7",
        "outputId": "f66c1fb5-b021-43fe-951d-0a8f17b243fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaning text data... this may take a moment.\n",
            "Cleaning complete. Here's a comparison:\n",
            "\n",
            "Original Review:\n",
            "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
            "\n",
            "Cleaned Review:\n",
            "one reviewers mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far away would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "# max_features=5000 means we only consider the 5000 most frequent words\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Create the TF-IDF features (X) and the target labels (y)\n",
        "X = tfidf_vectorizer.fit_transform(df['cleaned_review'])\n",
        "y = df['sentiment']\n",
        "\n",
        "print(\"\\nShape of the TF-IDF feature matrix (reviews, vocabulary_size):\")\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UdAlr1YepYx",
        "outputId": "8733a2a4-369a-4a4a-bebf-931cb7e2215e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of the TF-IDF feature matrix (reviews, vocabulary_size):\n",
            "(50000, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Split data into 80% for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "print(\"\\nTraining the Logistic Regression model...\")\n",
        "model = LogisticRegression(max_iter=1000) # Increased max_iter for convergence\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Model training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxWFGXDWg10a",
        "outputId": "16f002e4-2bc8-4ac7-876b-3029975b8ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the Logistic Regression model...\n",
            "Model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy and F1-score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Model F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Display a detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xug6QBh3g9yp",
        "outputId": "a2fdcc4b-9fd7-4180-e87d-90433bf16f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy: 0.8924\n",
            "Model F1-Score: 0.8947\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.90      0.88      0.89      4961\n",
            "    Positive       0.88      0.91      0.89      5039\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review_text):\n",
        "    \"\"\"\n",
        "    Takes a new review and predicts its sentiment.\n",
        "    \"\"\"\n",
        "    # 1. Clean the incoming text\n",
        "    cleaned_text = clean_text(review_text)\n",
        "\n",
        "    # 2. Convert the cleaned text to its TF-IDF representation\n",
        "    # Note: Use 'transform', not 'fit_transform', as the vocabulary is already learned\n",
        "    vectorized_text = tfidf_vectorizer.transform([cleaned_text])\n",
        "\n",
        "    # 3. Predict using the trained model\n",
        "    prediction = model.predict(vectorized_text)\n",
        "\n",
        "    # 4. Return the sentiment\n",
        "    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n",
        "\n",
        "# --- Example Usage ---\n",
        "new_review_1 = \"This was an absolutely fantastic movie. The acting was superb and the plot was thrilling!\"\n",
        "new_review_2 = \"I was really disappointed. The story was boring and it felt way too long.\"\n",
        "\n",
        "print(\"\\n--- Testing with new reviews ---\")\n",
        "print(f\"Review: '{new_review_1}'\")\n",
        "print(f\"Predicted Sentiment: {predict_sentiment(new_review_1)}\\n\")\n",
        "\n",
        "print(f\"Review: '{new_review_2}'\")\n",
        "print(f\"Predicted Sentiment: {predict_sentiment(new_review_2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHktTUJZhEun",
        "outputId": "5b22112a-be24-4523-f2ae-5e5901b1a606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing with new reviews ---\n",
            "Review: 'This was an absolutely fantastic movie. The acting was superb and the plot was thrilling!'\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Review: 'I was really disappointed. The story was boring and it felt way too long.'\n",
            "Predicted Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVB_RfAkhtqX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}